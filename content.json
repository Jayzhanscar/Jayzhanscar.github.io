{"meta":{"title":"詹灵杰博客","subtitle":null,"description":"当你真心渴望追求某种事物的话，整个宇宙都会联合起来帮你完成。  ——《牧羊少年奇幻之旅》","author":"zhanlingjie","url":"http://yoursite.com"},"pages":[{"title":"about","date":"2019-02-03T17:43:15.000Z","updated":"2019-02-03T19:18:31.488Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":"姓名：詹灵杰 职业： python研发工程师 联系方式: 18895309883 / 734422495 / zlj941020 简介： 目前居住在杭州梦想小镇，喜欢听民谣."},{"title":"tags","date":"2019-02-03T18:09:37.000Z","updated":"2019-02-03T18:09:37.281Z","comments":true,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""},{"title":"categories","date":"2019-02-03T18:50:50.000Z","updated":"2019-02-03T18:50:50.899Z","comments":true,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"关于celery介绍","slug":"关于celery介绍","date":"2019-02-03T19:04:43.000Z","updated":"2019-02-03T19:06:44.128Z","comments":true,"path":"2019/02/04/关于celery介绍/","link":"","permalink":"http://yoursite.com/2019/02/04/关于celery介绍/","excerpt":"1.Celery是什么 1.1 Celery 是一个由 Python 编写的简单、灵活、可靠的用来处理大量信息的分布式系统,它同时提供操作和维护分布式系统所需的工具(它本身不是一个任务队列， 它是 任务队列管理的工具， 它提供的接口可以帮助我们实现分布式任务队列)。 1.2 Celery 专注于实时任务处理，支持任务调度(跟rabbitMQ可实现多种exchange。) 说白了，它是一个分布式队列的管理工具，我们可以用 Celery 提供的接口快速实现并管理一个分布式的任务队列。","text":"1.Celery是什么 1.1 Celery 是一个由 Python 编写的简单、灵活、可靠的用来处理大量信息的分布式系统,它同时提供操作和维护分布式系统所需的工具(它本身不是一个任务队列， 它是 任务队列管理的工具， 它提供的接口可以帮助我们实现分布式任务队列)。 1.2 Celery 专注于实时任务处理，支持任务调度(跟rabbitMQ可实现多种exchange。) 说白了，它是一个分布式队列的管理工具，我们可以用 Celery 提供的接口快速实现并管理一个分布式的任务队列。 1.3 Celery 架构 消息中间件(message broker)（邮箱， 邮局）: 本身不提供消息服务，可以和第三方消息中间件集成，常用的有 redis mongodb rabbitMQ 任务执行单元(worker)（寄件人）: 是Celery提供的任务执行单元， worker并发的运行在分布式的系统节点中 任务执行结果存储(task result store)（收件人）：用来存储Worker执行的任务的结果，Celery支持以不同方式存储任务的结果，包括Redis，MongoDB，Django ORM，AMQP等 1.4 任务队列和消息队列 任务队列是一种在线或机器分发任务的机制 消息队列输入是工作的一个单元， 可以认为是一个任务，独立的职程（Worker）进程持续监视队列中是否有需要处理的新任务。 图解 2.简单示例2.1 创建一个celery实例 创建tasks.py文件12345678910import timefrom celery import Celeryapp = Celery('tasks', broker='redis:////127.0.0.1:6379/6', backend='redis:////127.0.0.1:6379/7')@app.taskdef add(x, y): time.sleep(10) return x + y ps: tasks为任务名称 设置reids为中间件 2.2 创建一个index.py文件调用并且检测任务、查看任务执行状态123456789101112131415161718192021222324#!/usr/bin/env python# -*- coding:utf-8 -*-from tasks import add, appfrom celery.result import AsyncResultimport time# 立即告知celery去执行add任务，并传入两个参数result = add.delay(4, 4)print(result.id)async = AsyncResult(id=result.id, app=app)time.sleep(3)if async.successful(): result = async.get() print(result, \"执行成功\") # result.forget() # 将结果删除elif async.failed(): print('执行失败')elif async.status == 'PENDING': print('任务等待中被执行')elif async.status == 'RETRY': print('任务异常后正在重试')elif async.status == 'STARTED': print('任务已经开始被执行') ps 如果使用redis作为任务队列中间人，在redis中存在两个键 celery 和 _kombu.binding.celery ， _kombu.binding.celery 表示有一名为 celery 的任务队列（Celery 默认），而 celery为默认队列中的任务列表，使用list类型，可以看看添加进去的任务数据。 2.3 执行命令详解 celery -A app.celery_tasks.celery worker -Q queue –loglevel=info A参数指定celery对象的位置，该app.celery_tasks.celery指的 是app包下面的celery_tasks.py模块的celery实例，注意一定是初始化后的实例， Q参数指的是该worker接收指定的队列的任务，这是为了当多个队列有不同的任务时可以独立；如果不设会接收所有的队列的任务； l参数指定worker的日志级别； 执行完毕后结果存储在redis中，查看redis中的数据，发现存在一个string类型的键值对celery-task-meta-064e4262-e1ba-4e87-b4a1-52dd1418188f:data该键值对的失效时间为24小时 2.4 消息主体分析 body : 是序列化后使用base64编码的信息，包括具体的任务参数，其中包括了需要执行的方法、参数和一些任务基本信息 content-encoding: 序列化数据编码方式 content-type: 任务数据的序列化方式，默认使用python内置的序列化模块pickle(ps: pickle模块支持的类型 所有python支持的原生类型：布尔值，整数，浮点数，复数，字符串，字节，None。由任何原生类型组成的列表，元组，字典和集合。函数，类，类的实例， 常用的方法：dumps,dump,loads,load) 123456789101112131415161718&#123; &quot;body&quot;: &quot;gAJ9cQAoWAQAAAB0YXNrcQFYCQAAAHRhc2tzLmFkZHECWAIAAABpZHEDWCQAAABjNDMwMzZkMi03Yzc3LTQ0MDUtOTYwNC1iZDc3ZTcyNzNlN2FxBFgEAAAAYXJnc3EFSwRLBIZxBlgGAAAAa3dhcmdzcQd9cQhYBwAAAHJldHJpZXNxCUsAWAMAAABldGFxCk5YBwAAAGV4cGlyZXNxC05YAwAAAHV0Y3EMiFgJAAAAY2FsbGJhY2tzcQ1OWAgAAABlcnJiYWNrc3EOTlgJAAAAdGltZWxpbWl0cQ9OToZxEFgHAAAAdGFza3NldHERTlgFAAAAY2hvcmRxEk51Lg==&quot;, &quot;content-encoding&quot;: &quot;binary&quot;, &quot;content-type&quot;: &quot;application/x-python-serialize&quot;, &quot;headers&quot;: &#123;&#125;, &quot;properties&quot;: &#123; &quot;reply_to&quot;: &quot;caa78c3a-618a-31f0-84a9-b79db708af02&quot;, &quot;correlation_id&quot;: &quot;c43036d2-7c77-4405-9604-bd77e7273e7a&quot;, &quot;delivery_mode&quot;: 2, &quot;delivery_info&quot;: &#123; &quot;priority&quot;: 0, &quot;exchange&quot;: &quot;celery&quot;, &quot;routing_key&quot;: &quot;celery&quot; &#125;, &quot;body_encoding&quot;: &quot;base64&quot;, &quot;delivery_tag&quot;: &quot;e7e288b5-ecbb-4ec6-912c-f42eb92dbd72&quot; &#125;&#125; 2.5 Celery配置1234567CELERY_DEFAULT_QUEUE：默认队列BROKER_URL : 代理人的网址CELERY_RESULT_BACKEND：结果存储地址CELERY_TASK_SERIALIZER：任务序列化方式CELERY_RESULT_SERIALIZER：任务执行结果序列化方式CELERY_TASK_RESULT_EXPIRES：任务过期时间CELERY_ACCEPT_CONTENT：指定任务接受的内容序列化类型(序列化)，一个列表； 2.6 获取执行任务执行结果的方法123456789r = func.delay(...)r.ready() # 查看任务状态，返回布尔值, 任务执行完成, 返回 True, 否则返回 False.r.wait() # 等待任务完成, 返回任务执行结果，很少使用；r.get(timeout=1) # 获取任务执行结果，可以设置等待时间r.result # 任务执行结果.r.state # PENDING, START, SUCCESS，任务当前的状态r.status # PENDING, START, SUCCESS，任务当前的状态r.successful # 任务成功返回truer.traceback # 如果任务抛出了一个异常，你也可以获取原始的回溯信息 2.7 celery的装饰方法celery.task task()把任务（函数）装饰成异步 12345@celery.task()def func(): # do something pass 可以重新定义任务的基类 1234567891011class MyTask(celery.Task): # 任务失败时执行 def on_failure(self, exc, task_id, args, kwargs, einfo): print('&#123;0!r&#125; failed: &#123;1!r&#125;'.format(task_id, exc)) # 任务成功时执行 def on_success(self, retval, task_id, args, kwargs): pass # 任务重试时执行 def on_retry(self, exc, task_id, args, kwargs, einfo): pass 参数 task_id : 任务id einfo：执行失败时任务详情 exc： 失败时的错误类型 retval： 任务成功时返回的执行结果 2.8 一份完整的配置文件123456789101112131415161718192021222324252627282930313233343536373839404142434445# 注意，celery4版本后，CELERY_BROKER_URL改为BROKER_URLBROKER_URL = 'amqp://username:passwd@host:port/虚拟主机名'# 指定结果的接受地址CELERY_RESULT_BACKEND = 'redis://username:passwd@host:port/db'# 指定任务序列化方式CELERY_TASK_SERIALIZER = 'msgpack' # 指定结果序列化方式CELERY_RESULT_SERIALIZER = 'msgpack'# 任务过期时间,celery任务执行结果的超时时间CELERY_TASK_RESULT_EXPIRES = 60 * 20 # 指定任务接受的序列化类型.CELERY_ACCEPT_CONTENT = [\"msgpack\"] # 任务发送完成是否需要确认，这一项对性能有一点影响 CELERY_ACKS_LATE = True # 压缩方案选择，可以是zlib, bzip2，默认是发送没有压缩的数据CELERY_MESSAGE_COMPRESSION = 'zlib' # 规定完成任务的时间CELERYD_TASK_TIME_LIMIT = 5 # 在5s内完成任务，否则执行该任务的worker将被杀死，任务移交给父进程# celery worker的并发数，默认是服务器的内核数目,也是命令行-c参数指定的数目CELERYD_CONCURRENCY = 4 # celery worker 每次去rabbitmq预取任务的数量CELERYD_PREFETCH_MULTIPLIER = 4 # 每个worker执行了多少任务就会死掉，默认是无限的CELERYD_MAX_TASKS_PER_CHILD = 40 # 设置默认的队列名称，如果一个消息不符合其他的队列就会放在默认队列里面，如果什么都不设置的话，数据都会发送到默认的队列中CELERY_DEFAULT_QUEUE = \"default\" # 设置详细的队列CELERY_QUEUES = &#123; \"default\": &#123; # 这是上面指定的默认队列 \"exchange\": \"default\", \"exchange_type\": \"direct\", \"routing_key\": \"default\" &#125;, \"topicqueue\": &#123; # 这是一个topic队列 凡是topictest开头的routing key都会被放到这个队列 \"routing_key\": \"topic.#\", \"exchange\": \"topic_exchange\", \"exchange_type\": \"topic\", &#125;, \"task_eeg\": &#123; # 设置扇形交换机 \"exchange\": \"tasks\", \"exchange_type\": \"fanout\", \"binding_key\": \"tasks\", &#125;, &#125; 2.8 Celery定时任务 指定定时任务并加入配置 重新启动worker 123456789101112131415# config.pyfrom datetime import timedeltafrom celery.schedules import crontab CELERYBEAT_SCHEDULE = &#123; 'ptask': &#123; 'task': 'tasks.period_task', 'schedule': timedelta(seconds=5), &#125;,&#125;# 添加定时任务@app.task(bind=True)def period_task(self): print 'period task done: &#123;0&#125;'.format(self.request.id) PS:时间如果涉及到datatime最好设置为UTC时间 启动定时任务进程 1celery -A task beat 2.9 链式任务链式任务就是异步或者定时执行的任务由多个子任务执行完成 123456789101112131415161718def update_page_info(url): # fetch_page -&gt; parse_page -&gt; store_page chain = fetch_page.s(url) | parse_page.s() | store_page_info.s(url) chain() @app.task()def fetch_page(url): return myhttplib.get(url) @app.task()def parse_page(page): return myparser.parse_document(page) @app.task(ignore_result=True)def store_page_info(info, url): PageInfo.objects.create(url=url, info=info) fetch_page.apply_async((url), link=[parse_page.s(), store_page_info.s(url)]) 3 Celery, rabbitmq实现exchange三种模式 celery的工作流程 borker : 消息中间件 worker : 任务执行单元 storgae: 任务执行结果存储 3.1 exchange 常用模式介绍(direct, fanout, topic, header) 当我们执行的任务需要根据特定的需要进行分类时，我们可以对任务创建多个队列进行， 每一个队列交换方式可以指定，需要注意的是：redis只能提供 direct exchange 方式， 也是默认指定的方式，所以我们把中间人换成了rabbitmq。 首先我们来了解一下交换模式有哪些？ Direct Exchange 模式 这种模式是rabbitmq（redis）自带的一种模式，所以我们在实际使用过程中只要指定routing_key就可以了，或者是指定队列名称即可。 ps: 如果我们指定的队列名称不在配置里面，那我们创建的这条消息任务会被自动废除，所以需要检查下配置里的队列是否正确，因为rabbitmq只具备存储队列的能力，不能存储消息信息。 Fanout Exchange 模式 fanout模式不用指定routing_key， 所有exchange_ type 是fanout的 Queue都会执行 所以队列和fanout可以多对多绑定。 Topic Exchange 模式 任何发送到Topic Exchange的消息都会被转发到所有关心RouteKey中指定话题的Queue上 这种模式较为复杂，简单来说，就是每个队列都有其关心的主题，所有的消息都带有一个“标题”(RouteKey)，Exchange会将消息转发到所有关注主题能与RouteKey模糊匹配的队列。 这种模式需要RouteKey，也许要提前绑定Exchange与Queue。 在进行绑定时，要提供一个该队列关心的主题，如“#.log.#”表示该队列关心所有涉及log的消息(一个RouteKey为”MQ.log.error”的消息会被转发到该队列)。 “#”表示0个或若干个关键字，“”表示一个关键字。如“log.”能与“log.warn”匹配，无法与“log.warn.timeout”匹配；但是“log.#”能与上述两者匹配。 同样，如果Exchange没有发现能够与RouteKey匹配的Queue，则会抛弃此消息。 3.2 在实际例子中如何去运用这三种模式 首先要安装rabitmq并且启动 rabbitmq-server 创建rabbitmq_config.py 文件， 并且把之前在tasks.py中引用的配置修改为rabbitmq_config，代码如下 1234567891011121314#coding:utf-8from celery.schedules import crontabimport sysimport ossys.path.insert(0, os.getcwd())CELERY_IMPORTS = (&quot;tasks&quot;, )CELERY_RESULT_BACKEND = &quot;amqp&quot;BROKER_HOST = &quot;localhost&quot;BROKER_PORT = 5672BROKER_USER = &quot;guest&quot;BROKER_PASSWORD = &quot;guest&quot;BROKER_VHOST = &quot;/&quot; 创建需要的交换方式 123456789101112131415161718default_exchange = Exchange('dedfault', type='direct')# 定义一个媒体交换机,类型是直连交换机media_exchange = Exchange('media', type='direct')# 定义一个image交换机,类型是fanout交换机image_exchange = Exchange('media', type='direct')# 创建三个队列，一个是默认队列，一个是video、一个imageCELERY_QUEUES = ( Queue('default', default_exchange, routing_key='default'), Queue('videos', media_exchange, routing_key='media.video'), Queue('images', media_exchange, routing_key='media.image'))# 定义默认队列和默认的交换机routing_keyCELERY_DEFAULT_QUEUE = 'default'CELERY_DEFAULT_EXCHANGE = 'default'CELERY_DEFAULT_ROUTING_KEY = 'default' 在tasks.py中指定任务 123456789101112131415161718192021222324252627282930# 视频压缩@app.taskdef video_compress(video_name): time.sleep(10) print('Compressing the:', video_name) return 'success'@app.taskdef video_upload(video_name): time.sleep(5) print( u'正在上传视频') return 'success'# 压缩照片@app.taskdef image_compress(image_name): time.sleep(10) print('Compressing the:', image_name) return 'success'# 其他任务@app.taskdef other(str): time.sleep(10) print ('Do other things') return 'success' 指定路由 1234567891011CELERY_ROUTES = (&#123;'tasks.image_compress': &#123; 'queue': 'images', 'routing_key': 'media.image' &#125;&#125;,&#123;'tasks.video_upload': &#123; 'queue': 'videos', 'routing_key': 'media.video' &#125;&#125;,&#123;'tasks.video_compress': &#123; 'queue': 'videos', 'routing_key': 'media.video' &#125;&#125;, ) 现在执行创建的任务在启动worker的时候可以分两种启动方式 第一种： 指定Queue 第二种 ： 不指定（全部执行） ps 为了更好的看到我们添加的队列，还有相应的交换模式，启动全部的队列 启动worker [queue]中包含了创建的队列，其他参数本文前面可以对照[tasks]中显示了我们所有的任务 123456789101112131415161718192021222324252627---- **** ----- --- * *** * -- Darwin-18.2.0-x86_64-i386-64bit 2018-12-28 15:38:00-- * - **** --- - ** ---------- [config]- ** ---------- .&gt; app: tasks:0x104e78d68- ** ---------- .&gt; transport: amqp://guest:**@localhost:5672//- ** ---------- .&gt; results: amqp://- *** --- * --- .&gt; concurrency: 4 (prefork)-- ******* ---- .&gt; task events: OFF (enable -E to monitor tasks in this worker)--- ***** ----- -------------- [queues] .&gt; default exchange=dedfault(direct) key=default .&gt; images exchange=media(direct) key=media.image .&gt; others exchange=other(fanout) key=other.others .&gt; videos exchange=media(direct) key=media.video[tasks] . tasks.add . tasks.dr . tasks.image_compress . tasks.other . tasks.period_task . tasks.task . tasks.video_compress . tasks.video_upload[2018-12-28 15:38:00,906: INFO/MainProcess] Connected to amqp://guest:**@127.0.0.1:5672// 执行结果(可以在rabbimq后台管理中看相关执行结果)： 12345678910111213[2018-12-28 15:38:00,906: INFO/MainProcess] Connected to amqp://guest:**@127.0.0.1:5672//[2018-12-28 15:38:00,933: INFO/MainProcess] mingle: searching for neighbors[2018-12-28 15:38:02,013: INFO/MainProcess] mingle: all alone[2018-12-28 15:38:02,091: INFO/MainProcess] celery@zhanlingjiedeMacBook-Pro.local ready.[2018-12-28 15:38:42,386: INFO/MainProcess] Received task: tasks.add[1fdfbc23-e106-49ab-ac25-d46c2b5e8960] [2018-12-28 15:38:42,429: INFO/ForkPoolWorker-3] Task tasks.add[1fdfbc23-e106-49ab-ac25-d46c2b5e8960] succeeded in 0.040455893002217636s: 5[2018-12-28 15:38:46,397: INFO/MainProcess] Received task: tasks.image_compress[cab797c5-eaae-4f11-b55c-041f4256ead9] [2018-12-28 15:38:46,410: INFO/MainProcess] Received task: tasks.other[0b00fd52-2251-42ef-9743-49df3f2906ed] [2018-12-28 15:38:56,401: WARNING/ForkPoolWorker-4] Compressing the:[2018-12-28 15:38:56,402: WARNING/ForkPoolWorker-4] 这是我上传的图片[2018-12-28 15:38:56,412: WARNING/ForkPoolWorker-3] Do other things[2018-12-28 15:38:56,447: INFO/ForkPoolWorker-3] Task tasks.other[0b00fd52-2251-42ef-9743-49df3f2906ed] succeeded in 10.036200570997607s: 'success'[2018-12-28 15:38:56,461: INFO/ForkPoolWorker-4] Task tasks.image_compress[cab797c5-eaae-4f11-b55c-041f4256ead9] succeeded in 10.061314186998061s: 'success' 补充一般在使用celery为了和实际场景结合会使用框架去使用 django + celery + redis(rabbitmq)","categories":[{"name":"python","slug":"python","permalink":"http://yoursite.com/categories/python/"}],"tags":[{"name":"django-celery","slug":"django-celery","permalink":"http://yoursite.com/tags/django-celery/"}]},{"title":"Continue writing","slug":"Continue-writing","date":"2019-02-03T18:57:16.000Z","updated":"2019-02-03T19:02:47.375Z","comments":true,"path":"2019/02/04/Continue-writing/","link":"","permalink":"http://yoursite.com/2019/02/04/Continue-writing/","excerpt":"","text":"从2017-8开始写自己的博客，主要是想对自己学习的东西做一个记录，为了方便后期解决问题查阅 经过两年的多的时间已经养成了习惯，与其说是博客用笔记更为恰当 很可惜在前段时间电脑重装了下，仓库也没有备份，写一篇继续篇再次记录自己的学习路程 开始于2019-2-4 大年三十","categories":[{"name":"随记","slug":"随记","permalink":"http://yoursite.com/categories/随记/"}],"tags":[{"name":"feelings","slug":"feelings","permalink":"http://yoursite.com/tags/feelings/"}]}]}